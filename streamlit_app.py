import streamlit as st
import pandas as pd
import os
import sys
import warnings
import glob
import logging
import datetime
import urllib.parse
import webbrowser
from io import BytesIO

# Set up logging
log_dir = "logs"
os.makedirs(log_dir, exist_ok=True)
log_file = os.path.join(log_dir, f"streamlit_app_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.log")

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# Log startup information
logging.info("="*50)
logging.info("STREAMLIT APP STARTED")
logging.info(f"Log file: {log_file}")
logging.info(f"Working directory: {os.getcwd()}")
logging.info(f"Python version: {sys.version}")
logging.info("="*50)

# Filter out the warning about print area
warnings.filterwarnings('ignore', message='Print area cannot be set to Defined name')

# Set page configuration
st.set_page_config(
    page_title="Checklistæ ¸å¯¹ç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for styling
st.markdown("""
<style>
    .main-header {
        font-size: 2.2rem;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 0.5rem;
        margin-top: 0;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #0D47A1;
        margin-top: 1rem;
        margin-bottom: 1rem;
    }
    .success-message {
        color: #4CAF50;
        font-weight: bold;
    }
    .error-message {
        color: #F44336;
        font-weight: bold;
    }
    .warning-message {
        color: #FF9800;
        font-weight: bold;
    }

    /* æ–‡ä»¶ä¸Šä¼ åŒºåŸŸæ ·å¼ä¼˜åŒ– */
    .upload-section {
        background-color: #E3F2FD;
        padding: 1.5rem;
        border-radius: 12px;
        border: 1px solid #BBDEFB;
        margin-bottom: 1rem;
        min-height: 100px;
        display: flex;
        flex-direction: column;
        justify-content: center;
        text-align: center;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }

    .upload-section h3 {
        margin-top: 0;
        margin-bottom: 0.5rem;
        color: #1565C0;
        font-size: 1.2rem;
        font-weight: 600;
    }

    /* è®¾ç½®åŒºåŸŸæ ·å¼ */
    .settings-section {
        background-color: #F3E5F5;
        padding: 1.5rem;
        border-radius: 12px;
        border: 1px solid #E1BEE7;
        margin-bottom: 1rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }

    /* å¤„ç†æŒ‰é’®åŒºåŸŸæ ·å¼ */
    .process-section {
        background-color: #E8F5E8;
        padding: 1.5rem;
        border-radius: 12px;
        border: 1px solid #C8E6C9;
        margin-bottom: 1rem;
        text-align: center;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }

    /* å¸®åŠ©åŒºåŸŸæ ·å¼ */
    .help-section {
        background-color: #FFF3E0;
        padding: 1.5rem;
        border-radius: 12px;
        border: 1px solid #FFCC02;
        margin-bottom: 1rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }

    /* ç´§å‡‘çš„åˆ—å¸ƒå±€ */
    .stColumns {
        gap: 1.5rem !important;
    }

    /* å‡å°‘æ ‡ç­¾é¡µé—´è· */
    .stTabs [data-baseweb="tab-list"] {
        gap: 0.5rem;
        margin-bottom: 1rem;
    }

    /* ä¼˜åŒ–æ–‡ä»¶ä¸Šä¼ å™¨æ ·å¼ */
    .stFileUploader {
        margin-bottom: 0.5rem;
    }

    /* ä¼˜åŒ–æˆåŠŸå’Œä¿¡æ¯æ¶ˆæ¯æ ·å¼ */
    .stSuccess, .stInfo {
        margin-top: 0.5rem;
        margin-bottom: 0.5rem;
    }

    /* ä¼˜åŒ–è¿›åº¦æ¡æ ·å¼ */
    .stProgress {
        margin-bottom: 0.5rem;
    }

    /* é˜²æ­¢æŒ‰é’®ç‚¹å‡»åé¡µé¢è·³è½¬çš„æ ·å¼ */
    .stDownloadButton > button {
        position: relative;
        z-index: 1;
    }

    .stButton > button {
        position: relative;
        z-index: 1;
    }

    /* ä¿æŒé¡µé¢ä½ç½®çš„æ ·å¼ */
    .main .block-container {
        scroll-behavior: smooth;
        padding-top: 1rem;
    }

    /* æ”¹å–„æŒ‰é’®çš„è§†è§‰åé¦ˆ */
    .stDownloadButton > button:hover,
    .stButton > button:hover {
        transform: translateY(-1px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        transition: all 0.2s ease;
    }

    /* é˜²æ­¢é¡µé¢é‡æ–°åŠ è½½æ—¶çš„é—ªçƒ */
    .stApp {
        transition: none;
    }

    /* ä¼˜åŒ–ä¾§è¾¹æ æ ·å¼ */
    .css-1d391kg {
        padding-top: 1rem;
    }

    /* ä¾§è¾¹æ æ–‡ä»¶ä¸Šä¼ å™¨æ ·å¼ */
    .css-1d391kg .stFileUploader {
        margin-bottom: 1rem;
    }

    /* ä¾§è¾¹æ æŒ‰é’®æ ·å¼ */
    .css-1d391kg .stButton > button {
        width: 100%;
        margin-top: 0.5rem;
    }

    /* ä¾§è¾¹æ æ ‡é¢˜æ ·å¼ */
    .css-1d391kg h2, .css-1d391kg h3 {
        margin-top: 1rem;
        margin-bottom: 0.5rem;
    }

    /* ä¾§è¾¹æ æ»‘å—æ ·å¼ */
    .css-1d391kg .stSlider {
        margin-bottom: 0.5rem;
    }

    /* å‡å°‘é¡µé¢é¡¶éƒ¨é—´è· */
    .block-container {
        padding-top: 1rem;
        padding-bottom: 1rem;
    }

    /* å‡å°‘å„ä¸ªç»„ä»¶ä¹‹é—´çš„é—´è· */
    .element-container {
        margin-bottom: 0.5rem;
    }

    /* ä¼˜åŒ–æ ‡ç­¾é¡µå®¹å™¨ */
    .stTabs > div > div > div > div {
        padding-top: 1rem;
    }
</style>

<script>
// é˜²æ­¢æŒ‰é’®ç‚¹å‡»åé¡µé¢è·³è½¬åˆ°é¡¶éƒ¨
document.addEventListener('DOMContentLoaded', function() {
    // ç›‘å¬æ‰€æœ‰æŒ‰é’®ç‚¹å‡»äº‹ä»¶
    document.addEventListener('click', function(e) {
        if (e.target.tagName === 'BUTTON' || e.target.closest('button')) {
            // è®°å½•å½“å‰æ»šåŠ¨ä½ç½®
            const scrollPosition = window.pageYOffset || document.documentElement.scrollTop;

            // å»¶è¿Ÿæ¢å¤æ»šåŠ¨ä½ç½®
            setTimeout(function() {
                window.scrollTo(0, scrollPosition);
            }, 100);
        }
    });
});
</script>
""", unsafe_allow_html=True)

# Create directories if they don't exist
os.makedirs('input', exist_ok=True)
os.makedirs('output', exist_ok=True)

# Main header
st.markdown("<h1 class='main-header'>Checklistæ ¸å¯¹ç³»ç»Ÿ</h1>", unsafe_allow_html=True)

# Sidebar
with st.sidebar:
    st.image("https://img.icons8.com/color/96/000000/invoice.png", width=80)
    st.markdown("## Checklistæ ¸å¯¹ç³»ç»Ÿ")
    st.markdown("**ç‰ˆæœ¬ 1.2**")

    st.markdown("---")

    # æ˜¾ç¤ºå½“å‰çŠ¶æ€
    st.markdown("### å½“å‰çŠ¶æ€")

    # æ£€æŸ¥æ–‡ä»¶ä¸Šä¼ çŠ¶æ€ï¼ˆä½¿ç”¨session stateï¼‰
    duty_uploaded = 'duty_rate_uploaded' in st.session_state and st.session_state.duty_rate_uploaded
    checklist_uploaded = 'checklist_uploaded' in st.session_state and st.session_state.checklist_uploaded
    invoices_uploaded = 'invoices_uploaded' in st.session_state and st.session_state.invoices_uploaded

    # æ–‡ä»¶ä¸Šä¼ çŠ¶æ€æ˜¾ç¤º
    if duty_uploaded:
        st.success("âœ… ç¨ç‡æ–‡ä»¶å·²ä¸Šä¼ ")
    else:
        st.info("â³ ç­‰å¾…ç¨ç‡æ–‡ä»¶")

    if checklist_uploaded:
        st.success("âœ… æ ¸å¯¹æ¸…å•å·²ä¸Šä¼ ")
    else:
        st.info("â³ ç­‰å¾…æ ¸å¯¹æ¸…å•")

    if invoices_uploaded:
        st.success("âœ… å‘ç¥¨æ–‡ä»¶å·²ä¸Šä¼ ")
    else:
        st.info("â³ ç­‰å¾…å‘ç¥¨æ–‡ä»¶")

    # æ˜¾ç¤ºæ•´ä½“è¿›åº¦
    total_files = 3
    uploaded_files = sum([duty_uploaded, checklist_uploaded, invoices_uploaded])
    progress = uploaded_files / total_files

    st.markdown("### ğŸ“ˆ ä¸Šä¼ è¿›åº¦")
    st.progress(progress)
    st.caption(f"å·²ä¸Šä¼  {uploaded_files}/{total_files} ä¸ªæ–‡ä»¶")

    st.markdown("---")

    # å¿«é€Ÿå¯¼èˆª
    st.markdown("### ğŸ§­ å¿«é€Ÿå¯¼èˆª")
    st.markdown("""
    - ğŸ“ **æ–‡ä»¶ä¸Šä¼ ä¸è®¾ç½®** - ä¸Šä¼ æ–‡ä»¶å¹¶é…ç½®å‚æ•°
    - ğŸ‘€ **æ•°æ®é¢„è§ˆ** - æŸ¥çœ‹ä¸Šä¼ çš„æ•°æ®
    - ğŸ“Š **å¤„ç†ç»“æœ** - æŸ¥çœ‹å¤„ç†åçš„æ•°æ®
    - ğŸ“‹ **å·®å¼‚æŠ¥å‘Š** - æŸ¥çœ‹æ¯”å¯¹å·®å¼‚
    - ğŸ“ **æ—¥å¿—** - æŸ¥çœ‹å¤„ç†æ—¥å¿—
    """)

    st.markdown("---")
    st.markdown("### â„¹ï¸ ç³»ç»Ÿä¿¡æ¯")
    st.caption("Â© 2025 Checklistæ ¸å¯¹ç³»ç»Ÿ")
    st.caption("ä¸“ä¸šçš„å‘ç¥¨æ ¸å¯¹è§£å†³æ–¹æ¡ˆ")

# Main content area with tabs
tab1, tab2, tab3, tab4, tab5 = st.tabs(["æ–‡ä»¶ä¸Šä¼ ", "æ•°æ®é¢„è§ˆ", "å¤„ç†ç»“æœ", "å·®å¼‚æŠ¥å‘Š", "æ—¥å¿—"])

def normalize_item_name(item_name):
    """
    æ ‡å‡†åŒ–Item Nameï¼Œç”¨äºæ›´å¥½çš„åŒ¹é…
    """
    if pd.isna(item_name) or item_name == '':
        return ''

    # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶è½¬ä¸ºå¤§å†™
    normalized = str(item_name).upper()

    # ç§»é™¤å¸¸è§çš„ç‰¹æ®Šå­—ç¬¦å’Œç©ºæ ¼
    normalized = normalized.replace(' ', '').replace('-', '').replace('_', '')
    normalized = normalized.replace(',', '.').replace(';', '.')

    # ç§»é™¤å¸¸è§çš„åç¼€
    suffixes_to_remove = ['PARTNO', 'PART', 'NO', 'NUM', 'NUMBER']
    for suffix in suffixes_to_remove:
        if normalized.endswith(suffix):
            normalized = normalized[:-len(suffix)]

    return normalized.strip()

def find_best_match(item_name, duty_rates_dict):
    """
    ä¸ºç»™å®šçš„item_nameåœ¨duty_rateså­—å…¸ä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…
    """
    if not item_name or pd.isna(item_name):
        return None

    normalized_item = normalize_item_name(item_name)

    # é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…
    if item_name in duty_rates_dict:
        return item_name

    # å°è¯•æ ‡å‡†åŒ–åçš„ç²¾ç¡®åŒ¹é…
    for duty_item in duty_rates_dict.keys():
        if normalize_item_name(duty_item) == normalized_item:
            return duty_item

    # å°è¯•éƒ¨åˆ†åŒ¹é…ï¼ˆåŒ…å«å…³ç³»ï¼‰- æ”¹è¿›ç‰ˆæœ¬
    best_match = None
    best_score = 0

    for duty_item in duty_rates_dict.keys():
        normalized_duty = normalize_item_name(duty_item)

        # è®¡ç®—åŒ¹é…åˆ†æ•°
        score = 0

        # å®Œå…¨åŒ…å«å…³ç³»
        if normalized_item in normalized_duty:
            score = len(normalized_item) / len(normalized_duty)
        elif normalized_duty in normalized_item:
            score = len(normalized_duty) / len(normalized_item)
        else:
            # è®¡ç®—å…¬å…±å­ä¸²é•¿åº¦
            common_length = 0
            min_len = min(len(normalized_item), len(normalized_duty))
            for i in range(min_len):
                if normalized_item[i] == normalized_duty[i]:
                    common_length += 1
                else:
                    break

            # å¦‚æœæœ‰è¶³å¤Ÿé•¿çš„å…¬å…±å‰ç¼€ï¼Œä¹Ÿè®¤ä¸ºæ˜¯åŒ¹é…
            if common_length >= 8:  # è‡³å°‘8ä¸ªå­—ç¬¦çš„å…¬å…±å‰ç¼€
                score = common_length / max(len(normalized_item), len(normalized_duty))

        # æ›´æ–°æœ€ä½³åŒ¹é…
        if score > best_score and score >= 0.7:  # è‡³å°‘70%çš„åŒ¹é…åº¦
            best_score = score
            best_match = duty_item

    return best_match

# Functions from the original scripts
def get_duty_rates(file_path):
    logging.info(f"Reading duty rates from: {file_path}")
    try:
        # Read duty_rate.xlsx
        df = pd.read_excel(file_path)
        logging.info(f"Duty rate file loaded. Shape: {df.shape}")
        logging.info(f"Duty rate columns: {df.columns.tolist()}")

        # Group by Item_Name and aggregate other columns
        logging.info("Grouping duty rates by 'Item Name'")
        grouped_df = df.groupby('Item Name').agg({
            'HSN1': lambda x: ' '.join(str(i) for i in x if pd.notna(i)),  # Concatenate HSN1 with space
            'HSN2': lambda x: ' '.join(str(i) for i in x if pd.notna(i)),  # Add HSN2
            'Final BCD': 'min',
            'Final SWS': 'min',
            'Final IGST': 'min'
        }).reset_index()

        logging.info(f"Grouped duty rates. Shape: {grouped_df.shape}")

        # Convert DataFrame to dictionary
        duty_dict = {}
        for _, row in grouped_df.iterrows():
            # Use HSN2 if HSN1 is empty
            hsn_value = row['HSN1'] if pd.notna(row['HSN1']) and row['HSN1'].strip() != '' else row['HSN2']
            duty_dict[row['Item Name']] = {
                'hsn': hsn_value,
                'bcd': row['Final BCD'],
                'sws': row['Final SWS'],
                'igst': row['Final IGST']
            }

        logging.info(f"Created duty dictionary with {len(duty_dict)} items")
        return duty_dict, df
    except Exception as e:
        error_msg = f"è¯»å–ç¨ç‡æ–‡ä»¶å¤±è´¥: {str(e)}"
        logging.error(error_msg)
        logging.exception("Exception details:")
        st.error(error_msg)
        return {}, None

def process_invoice_file(file_path, duty_rates):
    logging.info(f"Processing invoice file: {file_path}")
    try:
        # Get all sheet names
        excel_file = pd.ExcelFile(file_path)
        all_sheet_names = excel_file.sheet_names
        logging.info(f"All sheet names in invoice file: {all_sheet_names}")

        # Store original sheet names for accessing sheets
        original_sheet_names = excel_file.sheet_names[1:]  # Skip the first sheet
        logging.info(f"Processing sheets (skipping first): {original_sheet_names}")

        # Process sheet names for display and ID creation (remove CI- prefix and trim spaces)
        processed_sheet_names = [name.replace('CI-', '').strip() if name.startswith('CI-') else name.strip()
                      for name in original_sheet_names]
        logging.info(f"Processed sheet names: {processed_sheet_names}")

        # Initialize DataFrames for results
        all_invoices_df = pd.DataFrame()
        new_descriptions_df = pd.DataFrame()

        # Process each sheet
        for i, (original_sheet_name, processed_sheet_name) in enumerate(zip(original_sheet_names, processed_sheet_names)):
            logging.info(f"Processing sheet {i+1}/{len(original_sheet_names)}: {original_sheet_name}")
            # Read the sheet
            df = pd.read_excel(file_path, sheet_name=original_sheet_name)
            logging.info(f"Sheet data loaded. Shape: {df.shape}")
            if not df.empty:
                logging.info(f"First few columns: {df.columns[:5].tolist() if len(df.columns) > 5 else df.columns.tolist()}")

            # Create a new DataFrame for this sheet
            sheet_df = pd.DataFrame()

            # Add Item# column first
            sheet_df['Item#'] = df.iloc[:, 0]  # Assuming Item# is always the first column

            # IMPORTANT: Update these indices based on the printed columns
            column_indices = {
                'Item#': 0,
                'P/N': 2,
                'Desc': 3,
                'Qty': 5,
                'Price': 6,
                'Item_Name': 3,
            }
            logging.info(f"Using column indices: {column_indices}")

            # Then add other columns except Item# (since it's already added)
            for new_name, idx in column_indices.items():
                if new_name == 'Item#':
                    continue # Skip Item# as it's already added
                # For Item_Name column, split by '-' and take only the part before it
                if new_name == 'Item_Name':
                    sheet_df[new_name] = df.iloc[:, idx].apply(lambda x: str(x).split('-')[0].strip() if pd.notna(x) and '-' in str(x) else x)
                elif new_name == 'Desc':
                    # Clean the description text to only keep alphanumeric, dots, hyphens and parentheses
                    sheet_df[new_name] = df.iloc[:, idx].apply(lambda x: ''.join(char.upper() for char in str(x) if char.isalnum() or char in '.()').replace('Î¦', '').replace('Î©', '').replace('-', '').replace('Ï†', '') if pd.notna(x) else x)
                else:
                    sheet_df[new_name] = df.iloc[:, idx]

            # Create ID in the first column (trim spaces from Item# to ensure clean IDs)
            sheet_df.loc[1:,'ID'] = processed_sheet_name + '_' + sheet_df['Item#'].astype(str).str.strip()
            logging.info(f"Created IDs for sheet {original_sheet_name}")

            # Add duty rate columns after all other columns are set
            sheet_df['HSN'] = ''
            sheet_df['BCD'] = ''
            sheet_df['SWS'] = ''
            sheet_df['IGST'] = ''
            unique_desc = set()

            # Fill duty rate information and collect unmatched items
            new_items_count = 0
            for idx, row in sheet_df.iterrows():
                itemName = row['Item_Name']
                if pd.notna(itemName) and itemName != '':
                    # ä½¿ç”¨æ”¹è¿›çš„åŒ¹é…ç®—æ³•
                    matched_duty_item = find_best_match(itemName, duty_rates)

                    if matched_duty_item:
                        rates = duty_rates[matched_duty_item]
                        sheet_df.at[idx, 'HSN'] = rates['hsn']
                        sheet_df.at[idx, 'BCD'] = rates['bcd']
                        sheet_df.at[idx, 'SWS'] = rates['sws']
                        sheet_df.at[idx, 'IGST'] = rates['igst']

                        # è®°å½•åŒ¹é…ä¿¡æ¯ç”¨äºè°ƒè¯•
                        if matched_duty_item != itemName:
                            logging.info(f"Fuzzy match found: '{itemName}' -> '{matched_duty_item}'")
                    else:
                        sheet_df.at[idx, 'HSN'] = 'new item'
                        sheet_df.at[idx, 'BCD'] = 'new item'
                        sheet_df.at[idx, 'SWS'] = 'new item'
                        sheet_df.at[idx, 'IGST'] = 'new item'
                        if itemName not in unique_desc:
                            unique_desc.add(itemName)
                            new_items_count += 1
                            logging.info(f"No match found for item: '{itemName}' (normalized: '{normalize_item_name(itemName)}')")
                            # Add unmatched items to new_descriptions_df
                            new_descriptions_df = pd.concat([new_descriptions_df, pd.DataFrame({
                                'å‘ç¥¨åŠé¡¹å·': [str(row['ID'])],
                                'Item Name': [itemName],
                                'Final BCD': [''],
                                'Final SWS': [''],
                                'Final IGST': [''],
                                'HSN1': [''],
                                # æ·»åŠ å…¼å®¹æ—§ç‰ˆæœ¬çš„åˆ—ï¼Œç¡®ä¿ä¸ºå­—ç¬¦ä¸²ç±»å‹
                                'Duty': [''],
                                'Welfare': ['']
                            })], ignore_index=True)

            logging.info(f"Found {new_items_count} new items in sheet {original_sheet_name}")

            # Add this sheet's data to the combined DataFrame
            all_invoices_df = pd.concat([all_invoices_df, sheet_df], ignore_index=True)
            logging.info(f"Added sheet data to combined DataFrame. Current size: {all_invoices_df.shape}")

        logging.info(f"Completed processing invoice file. Final DataFrame shape: {all_invoices_df.shape}")
        logging.info(f"New items found: {len(new_descriptions_df)}")

        # Check for duplicate IDs
        duplicate_ids = all_invoices_df['ID'].value_counts()[all_invoices_df['ID'].value_counts() > 1]
        if not duplicate_ids.empty:
            logging.warning(f"Found {len(duplicate_ids)} duplicate IDs in processed invoices:")
            logging.warning(duplicate_ids.head(10).to_dict())  # Log first 10 duplicates
            # Remove duplicates
            all_invoices_df = all_invoices_df.drop_duplicates(subset=['ID'], keep='first')
            logging.info(f"Removed duplicates. New DataFrame shape: {all_invoices_df.shape}")

        # åœ¨returnå‰æ·»åŠ ç±»å‹è½¬æ¢
        # ç¡®ä¿ç‰¹å®šåˆ—ä¸ºå­—ç¬¦ä¸²ç±»å‹ï¼Œè§£å†³Arrowåºåˆ—åŒ–é—®é¢˜
        columns_to_convert = ['Item#', 'P/N', 'ID', 'Qty', 'Price', 'HSN', 'BCD', 'SWS', 'IGST', 'Item_Name']
        for col in columns_to_convert:
            if col in all_invoices_df.columns:
                all_invoices_df[col] = all_invoices_df[col].astype(str)

        # ç¡®ä¿new_descriptions_dfä¸­çš„æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œç‰¹åˆ«æ˜¯Dutyåˆ—
        if not new_descriptions_df.empty:
            # è®°å½•åˆ—åï¼Œå¸®åŠ©è°ƒè¯•
            logging.info(f"new_descriptions_df columns: {new_descriptions_df.columns.tolist()}")

            # é™¤äº†'Item Name'å¤–ï¼Œå°†æ‰€æœ‰åˆ—è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            for col in new_descriptions_df.columns:
                if col != 'Item Name':  # ä¿ç•™Item Nameåˆ—çš„åŸå§‹ç±»å‹
                    new_descriptions_df[col] = new_descriptions_df[col].astype(str)

            # ç‰¹åˆ«å¤„ç†å¯èƒ½å­˜åœ¨çš„Dutyå’ŒWelfareåˆ—ï¼ˆæ—§åç§°ï¼‰
            for col in ['Duty', 'Welfare', 'Final BCD', 'Final SWS', 'Final IGST', 'HSN1']:
                if col in new_descriptions_df.columns:
                    new_descriptions_df[col] = new_descriptions_df[col].astype(str)

        return all_invoices_df, new_descriptions_df
    except Exception as e:
        error_msg = f"å¤„ç†å‘ç¥¨æ–‡ä»¶å¤±è´¥: {str(e)}"
        logging.error(error_msg)
        logging.exception("Exception details:")
        st.error(error_msg)
        return pd.DataFrame(), pd.DataFrame()

def process_checklist(file_path):
    logging.info(f"Processing checklist file: {file_path}")
    try:
        # è¯»å–Excelæ–‡ä»¶
        df = pd.read_excel(file_path, skiprows=3)
        logging.info(f"Checklist file loaded. Shape: {df.shape}")
        logging.info(f"Checklist columns: {df.columns.tolist()}")

        # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å°è¯•æ‰¾åˆ°ç›¸ä¼¼çš„åˆ—å
        required_columns = ['P/N', 'Item#', 'Desc', 'Qty', 'Price', 'HSN', 'BCD', 'SWS', 'IGST']
        column_mapping = {}

        for req_col in required_columns:
            if req_col in df.columns:
                column_mapping[req_col] = req_col
            else:
                # å°è¯•æ‰¾åˆ°ç›¸ä¼¼çš„åˆ—åï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼Œå¿½ç•¥ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦ï¼‰
                for col in df.columns:
                    col_clean = str(col).strip().replace(' ', '').replace('/', '').replace('-', '').upper()
                    req_col_clean = req_col.replace('/', '').replace('-', '').upper()
                    if col_clean == req_col_clean or req_col_clean in col_clean:
                        column_mapping[req_col] = col
                        logging.info(f"Mapped column '{req_col}' to '{col}'")
                        break

                if req_col not in column_mapping:
                    logging.warning(f"Column '{req_col}' not found in checklist file")
                    column_mapping[req_col] = None

        logging.info(f"Column mapping: {column_mapping}")

        # åˆå§‹åŒ–æ–°çš„DataFrameç”¨äºå­˜å‚¨ç»“æœ
        result_rows = []
        current_invoice = None
        invoice_count = 0
        item_count = 0

        # éå†æ¯ä¸€è¡Œ
        for _, row in df.iterrows():  # ä½¿ç”¨ _ è¡¨ç¤ºä¸ä½¿ç”¨çš„ç´¢å¼•å˜é‡
            # æ£€æŸ¥æ˜¯å¦æ˜¯å‘ç¥¨è¡Œ - ä½¿ç”¨å®‰å…¨çš„åˆ—è®¿é—®
            pn_col = column_mapping.get('P/N')
            if pn_col and pn_col in df.columns:
                pn = str(row[pn_col]) if pd.notna(row[pn_col]) else ''
            else:
                # å¦‚æœæ²¡æœ‰P/Nåˆ—ï¼Œå°è¯•åœ¨ç¬¬ä¸€åˆ—æˆ–å…¶ä»–åˆ—ä¸­æŸ¥æ‰¾Invoiceä¿¡æ¯
                pn = ''
                for col in df.columns:
                    if pd.notna(row[col]) and 'Invoice:' in str(row[col]):
                        pn = str(row[col])
                        break

            if 'Invoice:' in str(pn):
                # æå–å‘ç¥¨å·å¹¶å»é™¤æ‰€æœ‰ç©ºæ ¼
                invoice_no = pn.split('Invoice:')[1].split('dt.')[0].strip().replace(' ', '')
                current_invoice = invoice_no
                invoice_count += 1
                logging.info(f"Found invoice #{invoice_count}: {invoice_no}")
                # ä¿å­˜å‘ç¥¨è¡Œ
                result_rows.append({
                    'Item#': pn,
                    'ID': None,
                    'P/N': None,
                    'Desc': None,
                    'Qty': None,
                    'Price': None,
                    'Item_Name': None,
                    'HSN': None,
                    'BCD': None,
                    'SWS': None,
                    'IGST': None
                })
            else:
                # å¤„ç†å¸¸è§„è¡Œ - ä½¿ç”¨å®‰å…¨çš„åˆ—è®¿é—®
                item_col = column_mapping.get('Item#')
                if item_col and item_col in df.columns and pd.notna(row[item_col]) and current_invoice:
                    # Convert Item# to integer before concatenating to remove the decimal and spaces
                    try:
                        item_num = int(float(row[item_col])) if pd.notna(row[item_col]) else 0
                        item_id = f"{current_invoice}_{item_num}"
                    except (ValueError, TypeError):
                        # Remove spaces from item number to ensure clean IDs
                        clean_item = str(row[item_col]).strip().replace(' ', '')
                        item_id = f"{current_invoice}_{clean_item}"

                    # å®‰å…¨è·å–Descåˆ—
                    desc_col = column_mapping.get('Desc')
                    if desc_col and desc_col in df.columns and pd.notna(row[desc_col]):
                        item_name = str(row[desc_col]).split('-')[0]
                        # ä¿®æ”¹item_nameçš„å¤„ç†é€»è¾‘
                        desc_parts = str(row[desc_col]).split('-PART NO')
                        desc = desc_parts[0]
                        # åªä¿ç•™å­—æ¯æ•°å­—å’Œç‚¹å·ï¼Œå¹¶è½¬æ¢ä¸ºå¤§å†™
                        desc = desc.replace('+OR-', '')
                        desc = desc.replace('DEG', '')
                        desc = desc.replace('-', '')
                        desc = ''.join(char for char in desc if char.isalnum() or char in '.()').upper()
                    else:
                        item_name = ''
                        desc = ''

                    item_count += 1

                    # åˆ›å»ºä¸€ä¸ªå®‰å…¨çš„å­—å…¸ï¼Œä½¿ç”¨æ˜ å°„çš„åˆ—å
                    def safe_get_value(col_name):
                        mapped_col = column_mapping.get(col_name)
                        if mapped_col and mapped_col in df.columns:
                            return row[mapped_col] if pd.notna(row[mapped_col]) else ''
                        return ''

                    item_dict = {
                        'Item#': safe_get_value('Item#'),
                        'ID': item_id,
                        'P/N': safe_get_value('P/N'),
                        'Desc': desc,
                        'Qty': safe_get_value('Qty'),
                        'Price': safe_get_value('Price'),
                        'Item_Name': item_name,
                        'HSN': '',
                        'BCD': '',
                        'SWS': '',
                        'IGST': '',
                    }

                    # å¤„ç†HSNåˆ—ï¼ˆå¯èƒ½æ˜¯æ•°å­—ï¼‰
                    hsn_value = safe_get_value('HSN')
                    if hsn_value and str(hsn_value).strip().isdigit():
                        item_dict['HSN'] = int(float(hsn_value))
                    else:
                        item_dict['HSN'] = hsn_value

                    # å¤„ç†å…¶ä»–æ•°å€¼åˆ—
                    for col in ['BCD', 'SWS', 'IGST']:
                        item_dict[col] = safe_get_value(col)

                    # ç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹
                    for key in ['Item#', 'P/N', 'ID', 'Qty', 'Price', 'HSN', 'BCD', 'SWS', 'IGST']:
                        if key in item_dict and item_dict[key] is not None:
                            item_dict[key] = str(item_dict[key])

                    result_rows.append(item_dict)

        # åˆ›å»ºç»“æœDataFrame
        result_df = pd.DataFrame(result_rows)
        logging.info(f"Processed checklist with {invoice_count} invoices and {item_count} items")
        logging.info(f"Final checklist DataFrame shape: {result_df.shape}")

        # å¦‚æœæ²¡æœ‰å¤„ç†åˆ°ä»»ä½•æ•°æ®ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
        if result_df.empty:
            logging.warning("No data was processed from checklist file")
            logging.warning(f"Available columns in file: {df.columns.tolist()}")
            logging.warning(f"Column mapping used: {column_mapping}")
            logging.warning("Please check if the file format matches expected structure")

            # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®ä»¥å¸®åŠ©è°ƒè¯•
            if not df.empty:
                logging.warning(f"First few rows of data:")
                for i, row in df.head(5).iterrows():
                    logging.warning(f"Row {i}: {row.to_dict()}")
        else:
            logging.info(f"Successfully processed checklist data")
            if not result_df.empty:
                logging.info(f"Sample processed data: {result_df.head(2).to_dict()}")

        # Check for duplicate IDs
        duplicate_ids = result_df['ID'].value_counts()[result_df['ID'].value_counts() > 1]
        if not duplicate_ids.empty:
            logging.warning(f"Found {len(duplicate_ids)} duplicate IDs in processed checklist:")
            logging.warning(duplicate_ids.head(10).to_dict())  # Log first 10 duplicates
            # Remove duplicates
            result_df = result_df.drop_duplicates(subset=['ID'], keep='first')
            logging.info(f"Removed duplicates. New DataFrame shape: {result_df.shape}")

        # åœ¨returnå‰æ·»åŠ ç±»å‹è½¬æ¢
        # ç¡®ä¿ç‰¹å®šåˆ—ä¸ºå­—ç¬¦ä¸²ç±»å‹ï¼Œè§£å†³Arrowåºåˆ—åŒ–é—®é¢˜
        columns_to_convert = ['Item#', 'P/N', 'ID', 'Qty', 'Price', 'HSN', 'BCD', 'SWS', 'IGST']
        for col in columns_to_convert:
            if col in result_df.columns:
                result_df[col] = result_df[col].astype(str)

        return result_df
    except Exception as e:
        error_msg = f"å¤„ç†æ ¸å¯¹æ¸…å•å¤±è´¥: {str(e)}"
        logging.error(error_msg)
        logging.exception("Exception details:")

        # æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ç»™ç”¨æˆ·
        if "KeyError" in str(e):
            missing_col = str(e).split("'")[1] if "'" in str(e) else "æœªçŸ¥åˆ—"
            detailed_msg = f"æ ¸å¯¹æ¸…å•æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—: '{missing_col}'"
            st.error(f"âŒ {detailed_msg}")
            st.info("ğŸ’¡ è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œç¡®ä¿åŒ…å«ä»¥ä¸‹åˆ—ï¼šItem#, P/N, Desc, Qty, Price, HSN, BCD, SWS, IGST")
        else:
            st.error(f"âŒ {error_msg}")
            st.info("ğŸ’¡ è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦ä¸ºæ­£ç¡®çš„Excelæ–‡ä»¶(.xlsx)")

        return pd.DataFrame()

def compare_excels(df1, df2, price_tolerance_pct=1.1):
    logging.info("Starting comparison between processed invoices and checklist")
    logging.info(f"Using price tolerance: {price_tolerance_pct}%")
    logging.info(f"DataFrame 1 (invoices) shape: {df1.shape}")
    logging.info(f"DataFrame 2 (checklist) shape: {df2.shape}")

    # è®°å½•ä¸¤ä¸ªDataFrameçš„åˆ—åï¼Œå¸®åŠ©è°ƒè¯•
    logging.info(f"DataFrame 1 columns: {df1.columns.tolist()}")
    logging.info(f"DataFrame 2 columns: {df2.columns.tolist()}")

    try:
        # æ£€æŸ¥IDåˆ—æ˜¯å¦å­˜åœ¨
        if 'ID' not in df1.columns:
            error_msg = "'ID' column not found in DataFrame 1"
            logging.error(error_msg)
            st.error(error_msg)
            return pd.DataFrame()

        if 'ID' not in df2.columns:
            error_msg = "'ID' column not found in DataFrame 2"
            logging.error(error_msg)
            st.error(error_msg)
            return pd.DataFrame()

        # æ£€æŸ¥ä¸ºnullçš„IDs
        null_ids_df1 = df1['ID'].isna().sum()
        null_ids_df2 = df2['ID'].isna().sum()
        if null_ids_df1 > 0:
            logging.warning(f"Found {null_ids_df1} null IDs in DataFrame 1 (invoices)")
        if null_ids_df2 > 0:
            logging.warning(f"Found {null_ids_df2} null IDs in DataFrame 2 (checklist)")

        # Check for duplicate IDs before comparison
        duplicate_ids_df1 = df1['ID'].value_counts()[df1['ID'].value_counts() > 1]
        duplicate_ids_df2 = df2['ID'].value_counts()[df2['ID'].value_counts() > 1]

        if not duplicate_ids_df1.empty:
            logging.warning(f"Found {len(duplicate_ids_df1)} duplicate IDs in DataFrame 1 (invoices)")
            logging.warning(f"First 5 duplicates: {duplicate_ids_df1.head().to_dict()}")
            # Remove duplicates from df1, keeping the first occurrence
            df1 = df1.drop_duplicates(subset=['ID'], keep='first')
            logging.info(f"Removed duplicates from DataFrame 1. New shape: {df1.shape}")

        if not duplicate_ids_df2.empty:
            logging.warning(f"Found {len(duplicate_ids_df2)} duplicate IDs in DataFrame 2 (checklist)")
            logging.warning(f"First 5 duplicates: {duplicate_ids_df2.head().to_dict()}")
            # Remove duplicates from df2, keeping the first occurrence
            df2 = df2.drop_duplicates(subset=['ID'], keep='first')
            logging.info(f"Removed duplicates from DataFrame 2. New shape: {df2.shape}")

        # ç¡®ä¿ä¸¤ä¸ª DataFrame çš„åˆ—åé¡ºåºä¸€è‡´
        # é¦–å…ˆæ£€æŸ¥ä¸¤ä¸ª DataFrame çš„åˆ—æ˜¯å¦ä¸€è‡´
        common_columns = list(set(df1.columns) & set(df2.columns))
        logging.info(f"Common columns between DataFrames: {common_columns}")

        # åªä½¿ç”¨ä¸¤ä¸ª DataFrame ä¸­éƒ½å­˜åœ¨çš„åˆ—è¿›è¡Œæ¯”è¾ƒ
        df1 = df1[common_columns]
        df2 = df2[common_columns]
        logging.info(f"Aligned columns between DataFrames")

        # ç”¨äºå­˜å‚¨å·®å¼‚ä¿¡æ¯
        diff_data = []
        # Keep track of processed IDs to avoid duplicates
        processed_ids = set()
        match_count = 0
        diff_count = 0

        for _, row1 in df1.iterrows():
            id1 = row1['ID']
            # Skip if this ID has already been processed or is None
            if id1 is None or pd.isna(id1) or id1 in processed_ids:
                continue

            # Add this ID to the processed set
            processed_ids.add(id1)

            # æŸ¥æ‰¾ df2 ä¸­å¯¹åº” ID çš„è¡Œ
            matching_row = df2[df2['ID'] == id1]
            if not matching_row.empty:
                match_count += 1
                row2 = matching_row.iloc[0]
                diff_cols = []
                for col in df1.columns[1:]:  # è·³è¿‡IDåˆ—
                    # è·³è¿‡Item_Nameåˆ—å’ŒItem#åˆ—çš„æ¯”å¯¹
                    if col == 'Item_Name' or col == 'Item#':
                        continue

                    # å¯¹Priceåˆ—ä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„è¯¯å·®èŒƒå›´
                    if col == 'Price':
                        if pd.notna(row1[col]) and pd.notna(row2[col]):
                            try:
                                # é¦–å…ˆå°è¯•å°†å€¼è½¬æ¢ä¸ºfloatç±»å‹
                                price1 = float(row1[col]) if isinstance(row1[col], str) else row1[col]
                                price2 = float(row2[col]) if isinstance(row2[col], str) else row2[col]

                                # è®¡ç®—å®¹å·®
                                tolerance = price1 * (price_tolerance_pct / 100)  # è½¬æ¢ä¸ºå°æ•°
                                if abs(price1 - price2) > tolerance:
                                    diff_cols.append(col)
                            except (ValueError, TypeError):
                                # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œè®°å½•é”™è¯¯å¹¶è·³è¿‡æ¯”è¾ƒ
                                logging.warning(f"æ— æ³•æ¯”è¾ƒä»·æ ¼: {row1[col]} vs {row2[col]}ï¼Œè·³è¿‡æ­¤æ¯”è¾ƒ")
                                # ä¿é™©èµ·è§ï¼Œæ ‡è®°ä¸ºæœ‰å·®å¼‚
                                diff_cols.append(col)
                    # å¯¹HSNåˆ—ç‰¹æ®Šå¤„ç†ï¼Œå¿½ç•¥æµ®ç‚¹æ•°å’Œæ•´æ•°çš„å·®å¼‚ï¼ˆå¦‚85423900.0å’Œ85423900ï¼‰
                    elif col == 'HSN':
                        if pd.notna(row1[col]) and pd.notna(row2[col]):
                            # å°†ä¸¤ä¸ªå€¼è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶å»é™¤å°æ•°ç‚¹åçš„é›¶
                            val1 = str(row1[col]).rstrip('0').rstrip('.') if '.' in str(row1[col]) else str(row1[col])
                            val2 = str(row2[col]).rstrip('0').rstrip('.') if '.' in str(row2[col]) else str(row2[col])

                            # è®°å½•HSNå€¼çš„æ¯”è¾ƒ
                            if val1 != val2:
                                logging.info(f"HSN difference found: {row1[col]} vs {row2[col]} (normalized: {val1} vs {val2})")
                                diff_cols.append(col)
                            else:
                                logging.debug(f"HSN values considered equal: {row1[col]} vs {row2[col]} (normalized: {val1} vs {val2})")
                    # å…¶ä»–åˆ—ä½¿ç”¨ç²¾ç¡®æ¯”å¯¹
                    elif row1[col] != row2[col]:
                        diff_cols.append(col)

                if diff_cols:
                    diff_count += 1
                    # åªåˆ›å»ºåŒ…å«IDå’Œæœ‰å·®å¼‚åˆ—çš„ä¿¡æ¯
                    diff_info = {'ID': id1}

                    # è®°å½•å·®å¼‚åˆ—
                    logging.info(f"ID {id1} çš„å·®å¼‚åˆ—: {diff_cols}")

                    # æŒ‰ç…§æœŸæœ›çš„åˆ—é¡ºåºå¤„ç†å·®å¼‚åˆ—
                    expected_columns = ['ID', 'P/N', 'Desc', 'HSN', 'BCD', 'SWS', 'IGST', 'Qty', 'Price']

                    # é¦–å…ˆå¤„ç†IDåˆ—
                    diff_info['ID'] = id1

                    # ç„¶åæŒ‰ç…§æœŸæœ›çš„é¡ºåºå¤„ç†å…¶ä»–åˆ—
                    for col in expected_columns:
                        if col != 'ID' and col in diff_cols:
                            # å¯¹æ•°å­—åˆ—ç‰¹æ®Šå¤„ç†æ˜¾ç¤ºæ ¼å¼ï¼Œå»é™¤å°æ•°ç‚¹åçš„é›¶
                            if col in ['HSN', 'BCD', 'SWS', 'IGST', 'Qty', 'Price']:
                                # å¤„ç†æ•°å€¼ï¼Œå»é™¤å°æ•°ç‚¹åçš„é›¶
                                val1 = str(row1[col]).rstrip('0').rstrip('.') if '.' in str(row1[col]) else str(row1[col])
                                val2 = str(row2[col]).rstrip('0').rstrip('.') if '.' in str(row2[col]) else str(row2[col])

                                # è·³è¿‡ç›¸åŒå€¼çš„æ˜¾ç¤º (ä¾‹å¦‚ 10 -> 10)
                                if val1 == val2:
                                    continue

                                # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºå€¼/NaNå€¼
                                def is_empty_value(val):
                                    return (val.lower() in ['nan', 'none', ''] or
                                           val.strip() == '' or
                                           val == 'nan')

                                val1_is_empty = is_empty_value(val1)
                                val2_is_empty = is_empty_value(val2)

                                # åªæœ‰å½“ä¸¤ä¸ªå€¼éƒ½ä¸ºç©ºæ—¶æ‰è·³è¿‡
                                if val1_is_empty and val2_is_empty:
                                    continue

                                # è·³è¿‡ç›¸åŒå€¼çš„æ˜¾ç¤º (ä¾‹å¦‚ nan -> nan)
                                if val1.lower() == val2.lower():
                                    continue

                                # å¤„ç†æ˜¾ç¤ºå€¼ï¼šç©ºå€¼æ˜¾ç¤ºä¸º "null"
                                display_val1 = 'null' if val1_is_empty else val1
                                display_val2 = 'null' if val2_is_empty else val2

                                # æ·»åŠ å·®å¼‚ä¿¡æ¯ï¼ˆæ ¼å¼ï¼šchecklistå€¼ -> invoiceå€¼ï¼‰
                                diff_info[f'{col}'] = f'{display_val2} -> {display_val1}'
                            else:
                                # è·³è¿‡ç›¸åŒå€¼çš„æ˜¾ç¤º
                                if row1[col] == row2[col]:
                                    continue

                                # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºå€¼/NaNå€¼
                                def is_empty_value_general(val):
                                    if pd.isna(val):
                                        return True
                                    val_str = str(val).strip().lower()
                                    return val_str in ['nan', 'none', ''] or val_str == ''

                                val1_is_empty = is_empty_value_general(row1[col])
                                val2_is_empty = is_empty_value_general(row2[col])

                                # åªæœ‰å½“ä¸¤ä¸ªå€¼éƒ½ä¸ºç©ºæ—¶æ‰è·³è¿‡
                                if val1_is_empty and val2_is_empty:
                                    continue

                                # è·³è¿‡ç›¸åŒå€¼çš„æ˜¾ç¤º (ä¾‹å¦‚ nan -> nan)
                                if str(row1[col]).lower() == str(row2[col]).lower():
                                    continue

                                # å¤„ç†æ˜¾ç¤ºå€¼ï¼šç©ºå€¼æ˜¾ç¤ºä¸º "null"
                                display_val1 = 'null' if val1_is_empty else str(row1[col])
                                display_val2 = 'null' if val2_is_empty else str(row2[col])

                                # æ·»åŠ å·®å¼‚ä¿¡æ¯ï¼ˆæ ¼å¼ï¼šchecklistå€¼ -> invoiceå€¼ï¼‰
                                diff_info[f'{col}'] = f'{display_val2} -> {display_val1}'

                    # åªæœ‰å½“diff_infoä¸­æœ‰é™¤äº†IDä»¥å¤–çš„å…¶ä»–åˆ—æ—¶æ‰æ·»åŠ åˆ°diff_data
                    if len(diff_info) > 1:
                        diff_data.append(diff_info)

        logging.info(f"Comparison complete. Found {match_count} matching IDs between files")
        logging.info(f"Found {diff_count} differences")

        if diff_data:
            diff_df = pd.DataFrame(diff_data)

            # åˆ—åå·²ç»æ˜¯ BCD å’Œ SWSï¼Œä¸éœ€è¦å†è¿›è¡Œæ˜ å°„

            # å®šä¹‰æœŸæœ›çš„åˆ—é¡ºåº (æŒ‰ç…§æŒ‡å®šé¡ºåº)
            expected_columns = ['ID', 'P/N', 'Desc', 'HSN', 'BCD', 'SWS', 'IGST', 'Qty', 'Price']

            # åªä¿ç•™å®é™…æœ‰æ•°æ®çš„åˆ—
            non_empty_columns = ['ID']  # IDåˆ—å§‹ç»ˆä¿ç•™

            # æ£€æŸ¥æ¯ä¸€åˆ—æ˜¯å¦æœ‰éç©º/énanæ•°æ®
            for col in diff_df.columns:
                if col != 'ID':  # è·³è¿‡IDåˆ—ï¼Œå› ä¸ºå·²ç»åŒ…å«
                    # æ£€æŸ¥åˆ—æ˜¯å¦åŒ…å«ä»»ä½•éç©ºå€¼
                    has_data = False
                    for val in diff_df[col]:
                        if pd.notna(val) and str(val).strip() != '' and str(val).lower() != 'nan' and str(val).lower() != 'none':
                            has_data = True
                            break

                    if has_data:
                        non_empty_columns.append(col)

            # ä¸¥æ ¼æŒ‰ç…§æœŸæœ›çš„åˆ—é¡ºåºæ’åºï¼ŒåªåŒ…å«å­˜åœ¨çš„åˆ—
            ordered_columns = []
            for col in expected_columns:
                if col in diff_df.columns and (col == 'ID' or col in non_empty_columns):
                    ordered_columns.append(col)
                    logging.info(f"æ·»åŠ åˆ—åˆ°æœ€ç»ˆæŠ¥å‘Š: {col}")
                elif col in expected_columns:
                    logging.info(f"åˆ— {col} ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œè·³è¿‡")

            # ä¸å†æ·»åŠ å…¶ä»–åˆ—ï¼Œç¡®ä¿ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šé¡ºåº
            logging.info(f"æœ€ç»ˆåˆ—é¡ºåº: {ordered_columns}")

            # åº”ç”¨æ–°çš„åˆ—é¡ºåº
            diff_df = diff_df[ordered_columns]

            logging.info(f"Created difference DataFrame with shape: {diff_df.shape}")
            logging.info(f"Columns in final report: {diff_df.columns.tolist()}")

            # æ·»åŠ ç±»å‹è½¬æ¢ï¼Œè§£å†³Arrowåºåˆ—åŒ–é—®é¢˜
            for col in diff_df.columns:
                # æ‰€æœ‰åˆ—éƒ½è½¬ä¸ºå­—ç¬¦ä¸²ï¼ŒåŒ…æ‹¬ä¹‹å‰æ’é™¤çš„Item Name
                diff_df[col] = diff_df[col].astype(str)

            # é¢å¤–å¤„ç†ï¼šç¡®ä¿æ²¡æœ‰å­—ç¬¦ä¸²å½¢å¼çš„'nan'æˆ–'none'
            for col in diff_df.columns:
                diff_df[col] = diff_df[col].apply(
                    lambda x: '' if x.lower() in ['nan', 'none'] else x
                )

            # ç‰¹åˆ«å¤„ç†å¯èƒ½å­˜åœ¨çš„Dutyå’ŒWelfareåˆ—ï¼ˆæ—§åç§°ï¼‰
            for old_col in ['Duty', 'Welfare']:
                if old_col in diff_df.columns:
                    diff_df[old_col] = diff_df[old_col].astype(str)
                    logging.info(f"è½¬æ¢äº†å·®å¼‚æŠ¥å‘Šä¸­çš„æ—§åˆ—å {old_col} ä¸ºå­—ç¬¦ä¸²ç±»å‹")

            return diff_df
        else:
            logging.info("No differences found between files")
            return pd.DataFrame()

    except Exception as e:
        error_msg = f"æ¯”è¾ƒæ–‡ä»¶å¤±è´¥: {str(e)}"
        logging.error(error_msg)
        logging.exception("Exception details:")
        st.error(error_msg)
        return pd.DataFrame()

def generate_email_draft(diff_report_df):
    """
    æ ¹æ®å·®å¼‚æŠ¥å‘Šç”Ÿæˆé‚®ä»¶è‰ç¨¿å†…å®¹
    """
    logging.info("ç”Ÿæˆé‚®ä»¶è‰ç¨¿å¼€å§‹")

    if diff_report_df.empty:
        logging.info("æ²¡æœ‰å·®å¼‚æ•°æ®ï¼Œæ— éœ€ç”Ÿæˆé‚®ä»¶è‰ç¨¿")
        return None

    try:
        email_body_lines = []
        email_body_lines.append("-------------------------------------------------------")
        email_body_lines.append("Hello ,")
        email_body_lines.append("")
        email_body_lines.append("Please revise the checklist as below:")

        # éå†æ¯ä¸€è¡Œå·®å¼‚æ•°æ®
        for _, row in diff_report_df.iterrows():
            invoice_id = row.get('ID', 'Unknown')

            # æ„å»ºé‚®ä»¶å†…å®¹è¡Œ
            corrections = []

            # æ£€æŸ¥å„ä¸ªå­—æ®µçš„å·®å¼‚å¹¶æ„å»ºä¿®æ­£ä¿¡æ¯
            if 'HSN' in row and pd.notna(row['HSN']) and str(row['HSN']).strip():
                # æå–æ­£ç¡®å€¼ï¼ˆæ ¼å¼ï¼šchecklistå€¼ -> invoiceå€¼ï¼Œæˆ‘ä»¬éœ€è¦invoiceå€¼ï¼‰
                hsn_correct = str(row['HSN']).split(' -> ')[1] if ' -> ' in str(row['HSN']) else str(row['HSN'])
                if hsn_correct != 'null':  # åªæœ‰å½“æ­£ç¡®å€¼ä¸æ˜¯nullæ—¶æ‰æ·»åŠ 
                    corrections.append(f"HSN {hsn_correct}")

            if 'BCD' in row and pd.notna(row['BCD']) and str(row['BCD']).strip():
                # æå–æ­£ç¡®å€¼ï¼ˆæ ¼å¼ï¼šchecklistå€¼ -> invoiceå€¼ï¼Œæˆ‘ä»¬éœ€è¦invoiceå€¼ï¼‰
                bcd_correct = str(row['BCD']).split(' -> ')[1] if ' -> ' in str(row['BCD']) else str(row['BCD'])
                if bcd_correct != 'null':  # åªæœ‰å½“æ­£ç¡®å€¼ä¸æ˜¯nullæ—¶æ‰æ·»åŠ 
                    corrections.append(f"BCD is {bcd_correct}")

            if 'SWS' in row and pd.notna(row['SWS']) and str(row['SWS']).strip():
                # æå–æ­£ç¡®å€¼ï¼ˆæ ¼å¼ï¼šchecklistå€¼ -> invoiceå€¼ï¼Œæˆ‘ä»¬éœ€è¦invoiceå€¼ï¼‰
                sws_correct = str(row['SWS']).split(' -> ')[1] if ' -> ' in str(row['SWS']) else str(row['SWS'])
                if sws_correct != 'null':  # åªæœ‰å½“æ­£ç¡®å€¼ä¸æ˜¯nullæ—¶æ‰æ·»åŠ 
                    corrections.append(f"SWS is {sws_correct}")

            if 'IGST' in row and pd.notna(row['IGST']) and str(row['IGST']).strip():
                # æå–æ­£ç¡®å€¼ï¼ˆæ ¼å¼ï¼šchecklistå€¼ -> invoiceå€¼ï¼Œæˆ‘ä»¬éœ€è¦invoiceå€¼ï¼‰
                hgst_correct = str(row['IGST']).split(' -> ')[1] if ' -> ' in str(row['IGST']) else str(row['IGST'])
                if hgst_correct != 'null':  # åªæœ‰å½“æ­£ç¡®å€¼ä¸æ˜¯nullæ—¶æ‰æ·»åŠ 
                    corrections.append(f"HGST is {hgst_correct}")

            if 'Qty' in row and pd.notna(row['Qty']) and str(row['Qty']).strip():
                # æå–æ­£ç¡®å€¼ï¼ˆæ ¼å¼ï¼šchecklistå€¼ -> invoiceå€¼ï¼Œæˆ‘ä»¬éœ€è¦invoiceå€¼ï¼‰
                qty_correct = str(row['Qty']).split(' -> ')[1] if ' -> ' in str(row['Qty']) else str(row['Qty'])
                if qty_correct != 'null':  # åªæœ‰å½“æ­£ç¡®å€¼ä¸æ˜¯nullæ—¶æ‰æ·»åŠ 
                    corrections.append(f"Qty is {qty_correct}")

            if 'Price' in row and pd.notna(row['Price']) and str(row['Price']).strip():
                # æå–æ­£ç¡®å€¼ï¼ˆæ ¼å¼ï¼šchecklistå€¼ -> invoiceå€¼ï¼Œæˆ‘ä»¬éœ€è¦invoiceå€¼ï¼‰
                price_correct = str(row['Price']).split(' -> ')[1] if ' -> ' in str(row['Price']) else str(row['Price'])
                if price_correct != 'null':  # åªæœ‰å½“æ­£ç¡®å€¼ä¸æ˜¯nullæ—¶æ‰æ·»åŠ 
                    corrections.append(f"Price is {price_correct}")

            if 'Desc' in row and pd.notna(row['Desc']) and str(row['Desc']).strip():
                # æå–æ­£ç¡®å€¼ï¼ˆæ ¼å¼ï¼šchecklistå€¼ -> invoiceå€¼ï¼Œæˆ‘ä»¬éœ€è¦invoiceå€¼ï¼‰
                desc_correct = str(row['Desc']).split(' -> ')[1] if ' -> ' in str(row['Desc']) else str(row['Desc'])
                if desc_correct != 'null':  # åªæœ‰å½“æ­£ç¡®å€¼ä¸æ˜¯nullæ—¶æ‰æ·»åŠ 
                    corrections.append(f"Description is {desc_correct}")

            if corrections:
                email_line = f"Invoice {invoice_id} use {' '.join(corrections)}ã€‚"
                email_body_lines.append(email_line)

        email_body_lines.append("")
        email_body_lines.append("Thank you!")
        email_body_lines.append("-------------------------------------------------------")

        email_content = "\n".join(email_body_lines)
        logging.info(f"é‚®ä»¶è‰ç¨¿ç”Ÿæˆå®Œæˆï¼Œå…±{len(diff_report_df)}æ¡å·®å¼‚è®°å½•")

        return email_content

    except Exception as e:
        error_msg = f"ç”Ÿæˆé‚®ä»¶è‰ç¨¿å¤±è´¥: {str(e)}"
        logging.error(error_msg)
        logging.exception("Exception details:")
        return None

def open_email_client(email_content, subject="Checklist Revision Required"):
    """
    æ‰“å¼€é»˜è®¤é‚®ä»¶å®¢æˆ·ç«¯å¹¶å¡«å……é‚®ä»¶å†…å®¹
    """
    try:
        # URLç¼–ç é‚®ä»¶å†…å®¹
        encoded_subject = urllib.parse.quote(subject)
        encoded_body = urllib.parse.quote(email_content)

        # æ„å»ºmailtoé“¾æ¥
        mailto_url = f"mailto:?subject={encoded_subject}&body={encoded_body}"

        # æ‰“å¼€é‚®ä»¶å®¢æˆ·ç«¯
        webbrowser.open(mailto_url)
        logging.info("å·²æ‰“å¼€é»˜è®¤é‚®ä»¶å®¢æˆ·ç«¯")
        return True

    except Exception as e:
        error_msg = f"æ‰“å¼€é‚®ä»¶å®¢æˆ·ç«¯å¤±è´¥: {str(e)}"
        logging.error(error_msg)
        logging.exception("Exception details:")
        return False

# File Upload Tab
with tab1:
    st.markdown("<h2 class='sub-header'>æ–‡ä»¶ä¸Šä¼ ä¸è®¾ç½®</h2>", unsafe_allow_html=True)

    # åˆ›å»ºä¸¤è¡Œå¸ƒå±€ï¼šç¬¬ä¸€è¡Œæ˜¯æ–‡ä»¶ä¸Šä¼ ï¼Œç¬¬äºŒè¡Œæ˜¯è®¾ç½®å’Œå¤„ç†

    # ç¬¬ä¸€è¡Œï¼šæ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.markdown("### ğŸ“ æ–‡ä»¶ä¸Šä¼ ")
    col1, col2, col3 = st.columns([1, 1, 1], gap="medium")

    with col1:
        st.markdown("""
        <div class='upload-section'>
            <h3>ç¨ç‡æ–‡ä»¶</h3>
        </div>
        """, unsafe_allow_html=True)
        duty_rate_file = st.file_uploader("ä¸Šä¼ ç¨ç‡æ–‡ä»¶", type=["xlsx"], key="duty_rate")
        if duty_rate_file is not None:
            st.success(f"âœ… å·²ä¸Šä¼ : {duty_rate_file.name}")
            # Save the uploaded file
            with open(os.path.join("input", "duty_rate.xlsx"), "wb") as f:
                f.write(duty_rate_file.getbuffer())
            # æ›´æ–°session state
            st.session_state.duty_rate_uploaded = True
        else:
            st.info("ğŸ“ è¯·ä¸Šä¼ ç¨ç‡æ–‡ä»¶")
            st.session_state.duty_rate_uploaded = False

    with col2:
        st.markdown("""
        <div class='upload-section'>
            <h3>æ ¸å¯¹æ¸…å•</h3>
        </div>
        """, unsafe_allow_html=True)
        checklist_file = st.file_uploader("ä¸Šä¼ æ ¸å¯¹æ¸…å•", type=["xlsx"], key="checklist")
        if checklist_file is not None:
            st.success(f"âœ… å·²ä¸Šä¼ : {checklist_file.name}")
            # Save the uploaded file
            with open(os.path.join("input", "processing_checklist.xlsx"), "wb") as f:
                f.write(checklist_file.getbuffer())
            # æ›´æ–°session state
            st.session_state.checklist_uploaded = True
        else:
            st.info("ğŸ“ è¯·ä¸Šä¼ æ ¸å¯¹æ¸…å•")
            st.session_state.checklist_uploaded = False

    with col3:
        st.markdown("""
        <div class='upload-section'>
            <h3>å‘ç¥¨æ–‡ä»¶</h3>
        </div>
        """, unsafe_allow_html=True)
        invoices_file = st.file_uploader("ä¸Šä¼ å‘ç¥¨æ–‡ä»¶", type=["xlsx"], key="invoices")
        if invoices_file is not None:
            st.success(f"âœ… å·²ä¸Šä¼ : {invoices_file.name}")
            # Save the uploaded file
            with open(os.path.join("input", "processing_invoices.xlsx"), "wb") as f:
                f.write(invoices_file.getbuffer())
            # æ›´æ–°session state
            st.session_state.invoices_uploaded = True
        else:
            st.info("ğŸ“ è¯·ä¸Šä¼ å‘ç¥¨æ–‡ä»¶")
            st.session_state.invoices_uploaded = False

    # æ·»åŠ åˆ†éš”çº¿
    st.markdown("---")

    # ç¬¬äºŒè¡Œï¼šè®¾ç½®å’Œå¤„ç†åŒºåŸŸ
    col_settings, col_process, col_help = st.columns([2, 1, 2], gap="large")

    with col_settings:
        st.markdown("""
        <div class='settings-section'>
            <h3>âš™ï¸ å¤„ç†è®¾ç½®</h3>
        </div>
        """, unsafe_allow_html=True)
        price_tolerance = st.slider("ä»·æ ¼æ¯”å¯¹è¯¯å·®èŒƒå›´ (%)", min_value=0.1, max_value=5.0, value=1.1, step=0.1)
        st.caption(f"å½“å‰è®¾ç½®: ä»·æ ¼å·®å¼‚è¶…è¿‡ {price_tolerance}% å°†è¢«æ ‡è®°")

    with col_process:
        st.markdown("""
        <div class='process-section'>
            <h3>ğŸš€ å¼€å§‹å¤„ç†</h3>
        </div>
        """, unsafe_allow_html=True)
        process_button = st.button("å¼€å§‹å¤„ç†", type="primary", use_container_width=True)

        # æ˜¾ç¤ºå¤„ç†çŠ¶æ€
        if st.session_state.get('duty_rate_uploaded', False) and \
           st.session_state.get('checklist_uploaded', False) and \
           st.session_state.get('invoices_uploaded', False):
            st.success("âœ… æ‰€æœ‰æ–‡ä»¶å·²å°±ç»ª")
        else:
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ‰€æœ‰æ–‡ä»¶")

    with col_help:
        st.markdown("""
        <div class='help-section'>
            <h3>ğŸ’¡ ä½¿ç”¨è¯´æ˜</h3>
        </div>
        """, unsafe_allow_html=True)
        with st.expander("æŸ¥çœ‹è¯¦ç»†æ­¥éª¤", expanded=False):
            st.markdown("""
            **æ“ä½œæ­¥éª¤ï¼š**
            1. ğŸ“„ ä¸Šä¼ ç¨ç‡æ–‡ä»¶ (duty_rate.xlsx)
            2. ğŸ“‹ ä¸Šä¼ æ ¸å¯¹æ¸…å• (processing_checklist.xlsx)
            3. ğŸ§¾ ä¸Šä¼ å‘ç¥¨æ–‡ä»¶ (processing_invoices*.xlsx)
            4. âš™ï¸ è°ƒæ•´ä»·æ ¼æ¯”å¯¹è¯¯å·®èŒƒå›´ï¼ˆå¯é€‰ï¼‰
            5. ğŸš€ ç‚¹å‡»"å¼€å§‹å¤„ç†"æŒ‰é’®
            6. ğŸ“Š åœ¨å…¶ä»–æ ‡ç­¾é¡µæŸ¥çœ‹å¤„ç†ç»“æœ

            **æ³¨æ„äº‹é¡¹ï¼š**
            - ç¡®ä¿æ–‡ä»¶æ ¼å¼ä¸º .xlsx
            - æ–‡ä»¶å¤§å°é™åˆ¶ä¸º 200MB
            - å¤„ç†æ—¶é—´å–å†³äºæ•°æ®é‡å¤§å°
            """)

# Data Preview Tab
with tab2:
    st.markdown("<h2 class='sub-header'>æ•°æ®é¢„è§ˆ</h2>", unsafe_allow_html=True)

    preview_tabs = st.tabs(["ç¨ç‡æ•°æ®", "æ ¸å¯¹æ¸…å•", "å‘ç¥¨æ•°æ®"])

    with preview_tabs[0]:
        if duty_rate_file is not None:
            try:
                duty_df = pd.read_excel(duty_rate_file)
                st.dataframe(duty_df, use_container_width=True)
            except Exception as e:
                st.error(f"æ— æ³•é¢„è§ˆç¨ç‡æ–‡ä»¶: {str(e)}")
        else:
            st.info("è¯·å…ˆä¸Šä¼ ç¨ç‡æ–‡ä»¶")

    with preview_tabs[1]:
        if checklist_file is not None:
            try:
                checklist_df = pd.read_excel(checklist_file, skiprows=3)
                st.dataframe(checklist_df, use_container_width=True)
            except Exception as e:
                st.error(f"æ— æ³•é¢„è§ˆæ ¸å¯¹æ¸…å•: {str(e)}")
        else:
            st.info("è¯·å…ˆä¸Šä¼ æ ¸å¯¹æ¸…å•")

    with preview_tabs[2]:
        if invoices_file is not None:
            try:
                excel_file = pd.ExcelFile(invoices_file)
                sheet_names = excel_file.sheet_names[1:]  # Skip the first sheet

                if sheet_names:
                    selected_sheet = st.selectbox("é€‰æ‹©å‘ç¥¨å·¥ä½œè¡¨", sheet_names)
                    invoices_df = pd.read_excel(invoices_file, sheet_name=selected_sheet)
                    st.dataframe(invoices_df, use_container_width=True)
                else:
                    st.warning("å‘ç¥¨æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°å·¥ä½œè¡¨")
            except Exception as e:
                st.error(f"æ— æ³•é¢„è§ˆå‘ç¥¨æ–‡ä»¶: {str(e)}")
        else:
            st.info("è¯·å…ˆä¸Šä¼ å‘ç¥¨æ–‡ä»¶")

# Process data when button is clicked
if process_button:
    logging.info("Process button clicked")
    if duty_rate_file is None or checklist_file is None or invoices_file is None:
        missing_files = []
        if duty_rate_file is None:
            missing_files.append("ç¨ç‡æ–‡ä»¶")
        if checklist_file is None:
            missing_files.append("æ ¸å¯¹æ¸…å•")
        if invoices_file is None:
            missing_files.append("å‘ç¥¨æ–‡ä»¶")
        error_msg = f"è¯·å…ˆä¸Šä¼ æ‰€æœ‰å¿…è¦çš„æ–‡ä»¶: {', '.join(missing_files)}"
        logging.error(error_msg)
        st.error(error_msg)
    else:
        logging.info("Starting data processing workflow")
        with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®..."):
            try:
                # Log input file paths
                duty_rate_path = os.path.join("input", "duty_rate.xlsx")
                invoices_path = os.path.join("input", "processing_invoices.xlsx")
                checklist_path = os.path.join("input", "processing_checklist.xlsx")

                logging.info(f"Input files: duty_rate={duty_rate_path}, invoices={invoices_path}, checklist={checklist_path}")
                logging.info(f"Price tolerance: {price_tolerance}%")

                # Process duty rates
                logging.info("Step 1: Processing duty rates")
                duty_rates, duty_df = get_duty_rates(duty_rate_path)

                # Process invoices
                logging.info("Step 2: Processing invoices")
                processed_invoices, new_items = process_invoice_file(invoices_path, duty_rates)

                # Process checklist
                logging.info("Step 3: Processing checklist")
                processed_checklist = process_checklist(checklist_path)

                # Compare the processed files
                logging.info("Step 4: Comparing processed files")
                diff_report = compare_excels(processed_invoices, processed_checklist, price_tolerance)

                # Save the processed files
                logging.info("Step 5: Saving output files")
                processed_invoices_path = os.path.join("output", "processed_invoices.xlsx")
                processed_checklist_path = os.path.join("output", "processed_checklist.xlsx")
                processed_report_path = os.path.join("output", "processed_report.xlsx")

                try:
                    # Save the diff report if it's not empty
                    if not diff_report.empty:
                        # åœ¨å¯¼å‡ºå‰ç¡®ä¿æ²¡æœ‰NaNå€¼
                        export_diff_report = diff_report.copy()

                        # å°†æ‰€æœ‰NaNå€¼æ›¿æ¢ä¸ºç©ºå­—ç¬¦ä¸²
                        export_diff_report = export_diff_report.fillna('')

                        # é¢å¤–å¤„ç†ï¼šç¡®ä¿æ²¡æœ‰å­—ç¬¦ä¸²å½¢å¼çš„'nan'æˆ–'none'
                        for col in export_diff_report.columns:
                            export_diff_report[col] = export_diff_report[col].apply(
                                lambda x: '' if isinstance(x, str) and x.lower() in ['nan', 'none'] else x
                            )

                        # ä½¿ç”¨xlsxwriterå¼•æ“ä¿å­˜ï¼Œä»¥ä¾¿è®¾ç½®åˆ—å®½
                        with pd.ExcelWriter(processed_report_path, engine='xlsxwriter') as writer:
                            export_diff_report.to_excel(writer, index=False, sheet_name='å·®å¼‚æŠ¥å‘Š')

                            # è·å–å·¥ä½œè¡¨
                            worksheet = writer.sheets['å·®å¼‚æŠ¥å‘Š']

                            # è®¾ç½®åˆ—å®½ - é™¤äº†DESCå­—æ®µå¤–çš„æ‰€æœ‰åˆ—éƒ½å®½ä¸€å€
                            for i, col in enumerate(export_diff_report.columns):
                                worksheet.set_column(i, i, 22)

                        logging.info(f"Saved diff report to {processed_report_path} with custom column widths")

                        # åˆ›å»ºç”¨äºè‡ªåŠ¨ä¸‹è½½çš„BytesIOå¯¹è±¡
                        report_buffer = BytesIO()
                        with pd.ExcelWriter(report_buffer, engine='xlsxwriter') as writer:
                            # ä½¿ç”¨å·²ç»å¤„ç†è¿‡NaNçš„export_diff_report
                            export_diff_report.to_excel(writer, index=False, sheet_name='å·®å¼‚æŠ¥å‘Š')

                            # è·å–å·¥ä½œè¡¨
                            worksheet = writer.sheets['å·®å¼‚æŠ¥å‘Š']

                            # è®¾ç½®åˆ—å®½ - é™¤äº†DESCå­—æ®µå¤–çš„æ‰€æœ‰åˆ—éƒ½å®½ä¸€å€
                            for i, col in enumerate(export_diff_report.columns):
                                worksheet.set_column(i, i, 22)

                        report_buffer.seek(0)

                        # è®¾ç½®ä¼šè¯çŠ¶æ€å˜é‡ï¼Œç”¨äºè‡ªåŠ¨ä¸‹è½½
                        st.session_state.auto_download_report = report_buffer
                        st.session_state.show_download_button = True

                        # ç”Ÿæˆé‚®ä»¶è‰ç¨¿
                        logging.info("Step 6: Generating email draft")
                        email_content = generate_email_draft(diff_report)
                        if email_content:
                            st.session_state.email_draft_content = email_content
                            st.session_state.show_email_button = True
                            logging.info("é‚®ä»¶è‰ç¨¿ç”ŸæˆæˆåŠŸ")
                        else:
                            st.session_state.show_email_button = False
                    else:
                        logging.info("No differences found, skipping diff report creation")
                        st.session_state.show_download_button = False
                        st.session_state.show_email_button = False
                except Exception as e:
                    logging.error(f"Error saving output files: {str(e)}")
                    logging.exception("Exception details:")
                    st.error(f"ä¿å­˜è¾“å‡ºæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")

                # Save new items if any
                if not new_items.empty:
                    logging.info(f"Found {len(new_items)} new items, saving to added_new_items.xlsx")
                    # Create a new Excel file with the original data
                    new_items_path = os.path.join("output", "added_new_items.xlsx")
                    try:
                        with pd.ExcelWriter(new_items_path, engine='xlsxwriter') as writer:
                            # æ£€æŸ¥duty_dfæ˜¯å¦ä¸ºNone
                            if duty_df is not None:
                                duty_df.to_excel(writer, index=False, sheet_name='CCTV')

                                # è·å–CCTVå·¥ä½œè¡¨å¹¶è®¾ç½®åˆ—å®½
                                worksheet_cctv = writer.sheets['CCTV']
                                for i, col in enumerate(duty_df.columns):
                                    # è®¡ç®—åˆ—çš„å®½åº¦
                                    max_len = max(
                                        duty_df[col].astype(str).map(len).max(),  # æœ€é•¿å†…å®¹
                                        len(str(col))  # åˆ—åé•¿åº¦
                                    ) + 2  # æ·»åŠ ä¸€äº›é¢å¤–ç©ºé—´

                                    # é™¤äº†æè¿°ç±»åˆ—å¤–çš„æ‰€æœ‰åˆ—éƒ½å®½ä¸€å€
                                    if col != 'Item Name' and 'Desc' not in col:
                                        max_len = max_len * 1.2

                                    # è®¾ç½®åˆ—å®½
                                    worksheet_cctv.set_column(i, i, max_len)
                            else:
                                logging.warning("duty_df is None, skipping CCTV sheet creation")

                            # Add new descriptions to a new sheet with required columns
                            required_columns = ['å‘ç¥¨åŠé¡¹å·', 'Item Name', 'Final BCD', 'Final SWS', 'Final IGST', 'HSN1']
                            new_items[required_columns].to_excel(writer, sheet_name='newDutyRate', index=False)

                            # è·å–newDutyRateå·¥ä½œè¡¨å¹¶è®¾ç½®åˆ—å®½
                            worksheet_new = writer.sheets['newDutyRate']
                            for i, col in enumerate(required_columns):
                                # è®¡ç®—åˆ—çš„å®½åº¦
                                max_len = max(
                                    new_items[col].astype(str).map(len).max(),  # æœ€é•¿å†…å®¹
                                    len(str(col))  # åˆ—åé•¿åº¦
                                ) + 2  # æ·»åŠ ä¸€äº›é¢å¤–ç©ºé—´

                                # é™¤äº†æè¿°ç±»åˆ—å¤–çš„æ‰€æœ‰åˆ—éƒ½å®½ä¸€å€
                                if col != 'Item Name':
                                    max_len = max_len * 1.2

                                # è®¾ç½®åˆ—å®½
                                worksheet_new.set_column(i, i, max_len)

                        logging.info(f"Saved new items to {new_items_path} with custom column widths")
                    except Exception as e:
                        logging.error(f"Error saving new items: {str(e)}")
                        logging.exception("Exception details:")
                        st.error(f"ä¿å­˜æ–°é¡¹ç›®æ—¶å‡ºé”™: {str(e)}")

                logging.info("Data processing completed successfully")
                st.success("æ•°æ®å¤„ç†å®Œæˆï¼")
            except Exception as e:
                error_msg = f"å¤„ç†æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
                logging.error(error_msg)
                logging.exception("Exception details:")
                st.error(error_msg)

# Results Tab
with tab3:
    st.markdown("<h2 class='sub-header'>å¤„ç†ç»“æœ</h2>", unsafe_allow_html=True)

    results_tabs = st.tabs(["å¤„ç†åçš„å‘ç¥¨", "å¤„ç†åçš„æ ¸å¯¹æ¸…å•", "æ–°å¢ç¨ç‡é¡¹"])

    with results_tabs[0]:
        processed_invoices_path = os.path.join("output", "processed_invoices.xlsx")
        if os.path.exists(processed_invoices_path):
            try:
                processed_invoices_df = pd.read_excel(processed_invoices_path)

                # æ·»åŠ ç±»å‹è½¬æ¢ï¼Œè§£å†³Arrowåºåˆ—åŒ–é—®é¢˜
                columns_to_convert = ['Item#', 'P/N', 'ID', 'Qty', 'Price', 'HSN', 'BCD', 'SWS', 'IGST', 'Item_Name']
                for col in columns_to_convert:
                    if col in processed_invoices_df.columns:
                        processed_invoices_df[col] = processed_invoices_df[col].astype(str)

                # ç‰¹åˆ«å¤„ç†å¯èƒ½å­˜åœ¨çš„Dutyå’ŒWelfareåˆ—ï¼ˆæ—§åç§°ï¼‰
                for old_col in ['Duty', 'Welfare']:
                    if old_col in processed_invoices_df.columns:
                        processed_invoices_df[old_col] = processed_invoices_df[old_col].astype(str)
                        logging.info(f"è½¬æ¢äº†å¤„ç†åå‘ç¥¨ä¸­çš„æ—§åˆ—å {old_col} ä¸ºå­—ç¬¦ä¸²ç±»å‹")

                st.dataframe(processed_invoices_df, use_container_width=True)

                # Download button
                with open(processed_invoices_path, "rb") as file:
                    st.download_button(
                        label="ä¸‹è½½å¤„ç†åçš„å‘ç¥¨",
                        data=file,
                        file_name="processed_invoices.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
            except Exception as e:
                st.error(f"æ— æ³•åŠ è½½å¤„ç†åçš„å‘ç¥¨: {str(e)}")
        else:
            st.info("è¯·å…ˆå¤„ç†æ•°æ®")

    with results_tabs[1]:
        processed_checklist_path = os.path.join("output", "processed_checklist.xlsx")
        if os.path.exists(processed_checklist_path):
            try:
                processed_checklist_df = pd.read_excel(processed_checklist_path)

                # æ·»åŠ ç±»å‹è½¬æ¢ï¼Œè§£å†³Arrowåºåˆ—åŒ–é—®é¢˜
                columns_to_convert = ['Item#', 'P/N', 'ID', 'Qty', 'Price', 'HSN', 'BCD', 'SWS', 'IGST', 'Item_Name']
                for col in columns_to_convert:
                    if col in processed_checklist_df.columns:
                        processed_checklist_df[col] = processed_checklist_df[col].astype(str)

                # ç‰¹åˆ«å¤„ç†å¯èƒ½å­˜åœ¨çš„Dutyå’ŒWelfareåˆ—ï¼ˆæ—§åç§°ï¼‰
                for old_col in ['Duty', 'Welfare']:
                    if old_col in processed_checklist_df.columns:
                        processed_checklist_df[old_col] = processed_checklist_df[old_col].astype(str)
                        logging.info(f"è½¬æ¢äº†å¤„ç†åæ ¸å¯¹æ¸…å•ä¸­çš„æ—§åˆ—å {old_col} ä¸ºå­—ç¬¦ä¸²ç±»å‹")

                st.dataframe(processed_checklist_df, use_container_width=True)

                # Download button
                with open(processed_checklist_path, "rb") as file:
                    st.download_button(
                        label="ä¸‹è½½å¤„ç†åçš„æ ¸å¯¹æ¸…å•",
                        data=file,
                        file_name="processed_checklist.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
            except Exception as e:
                st.error(f"æ— æ³•åŠ è½½å¤„ç†åçš„æ ¸å¯¹æ¸…å•: {str(e)}")
        else:
            st.info("è¯·å…ˆå¤„ç†æ•°æ®")

    with results_tabs[2]:
        new_items_path = os.path.join("output", "added_new_items.xlsx")
        if os.path.exists(new_items_path):
            try:
                excel_file = pd.ExcelFile(new_items_path)
                sheet_names = excel_file.sheet_names

                if 'newDutyRate' in sheet_names:
                    new_items_df = pd.read_excel(new_items_path, sheet_name='newDutyRate')
                    if not new_items_df.empty:
                        # æ·»åŠ ç±»å‹è½¬æ¢ - åŒ…æ‹¬Item Nameä¹Ÿè½¬ä¸ºå­—ç¬¦ä¸²
                        for col in new_items_df.columns:
                            # æ‰€æœ‰åˆ—éƒ½è½¬ä¸ºå­—ç¬¦ä¸²ï¼Œä¸å†ç‰¹æ®Šå¤„ç†Item Name
                            new_items_df[col] = new_items_df[col].astype(str)

                        # ç‰¹åˆ«å¤„ç†å¯èƒ½å­˜åœ¨çš„Dutyå’ŒWelfareåˆ—ï¼ˆæ—§åç§°ï¼‰
                        for old_col, new_col in [('Duty', 'BCD'), ('Welfare', 'SWS')]:
                            if old_col in new_items_df.columns:
                                new_items_df[old_col] = new_items_df[old_col].astype(str)
                                logging.info(f"è½¬æ¢äº†æ—§åˆ—å {old_col} ä¸ºå­—ç¬¦ä¸²ç±»å‹")

                        st.dataframe(new_items_df, use_container_width=True)

                        # Download button
                        with open(new_items_path, "rb") as file:
                            st.download_button(
                                label="ä¸‹è½½æ–°å¢ç¨ç‡é¡¹",
                                data=file,
                                file_name="added_new_items.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                    else:
                        st.info("æ²¡æœ‰å‘ç°æ–°å¢ç¨ç‡é¡¹")
                else:
                    st.info("æ²¡æœ‰å‘ç°æ–°å¢ç¨ç‡é¡¹")
            except Exception as e:
                st.error(f"æ— æ³•åŠ è½½æ–°å¢ç¨ç‡é¡¹: {str(e)}")
        else:
            st.info("æ²¡æœ‰å‘ç°æ–°å¢ç¨ç‡é¡¹æˆ–è¯·å…ˆå¤„ç†æ•°æ®")

# Diff Report Tab
with tab4:
    st.markdown("<h2 class='sub-header'>å·®å¼‚æŠ¥å‘Š</h2>", unsafe_allow_html=True)

    diff_report_path = os.path.join("output", "processed_report.xlsx")
    if os.path.exists(diff_report_path):
        try:
            diff_report_df = pd.read_excel(diff_report_path)

            # æ·»åŠ ç±»å‹è½¬æ¢ï¼Œè§£å†³Arrowåºåˆ—åŒ–é—®é¢˜
            for col in diff_report_df.columns:
                # æ‰€æœ‰åˆ—éƒ½è½¬ä¸ºå­—ç¬¦ä¸²
                diff_report_df[col] = diff_report_df[col].astype(str)

            # é¢å¤–å¤„ç†ï¼šç¡®ä¿æ²¡æœ‰å­—ç¬¦ä¸²å½¢å¼çš„'nan'æˆ–'none'
            for col in diff_report_df.columns:
                diff_report_df[col] = diff_report_df[col].apply(
                    lambda x: '' if isinstance(x, str) and x.lower() in ['nan', 'none'] else x
                )

            if not diff_report_df.empty:
                st.dataframe(diff_report_df, use_container_width=True)

                col1, col2 = st.columns(2)

                with col1:
                    # ä¿®æ”¹ä¸‹è½½æŒ‰é’®ï¼Œæ·»åŠ use_container_width=Trueæ¥é˜²æ­¢è·³è½¬
                    with open(diff_report_path, "rb") as file:
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½å·®å¼‚æŠ¥å‘Š",
                            data=file,
                            file_name="processed_report.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True,
                            help="ä¸‹è½½å·®å¼‚æ¯”å¯¹æŠ¥å‘Šæ–‡ä»¶"
                        )

                with col2:
                    # æ”¹è¿›é‚®ä»¶è‰ç¨¿æŒ‰é’®ï¼Œä½¿ç”¨æ›´å¥½çš„çŠ¶æ€ç®¡ç†
                    # åˆå§‹åŒ–é‚®ä»¶ç”ŸæˆçŠ¶æ€
                    if 'email_button_clicked' not in st.session_state:
                        st.session_state.email_button_clicked = False

                    if st.button("ğŸ“§ ç”Ÿæˆé€šçŸ¥é‚®ä»¶è‰ç¨¿", type="secondary", key="generate_email_button", use_container_width=True):
                        # è®¾ç½®æŒ‰é’®ç‚¹å‡»çŠ¶æ€
                        st.session_state.email_button_clicked = True

                        email_content = generate_email_draft(diff_report_df)
                        if email_content:
                            # æ˜¾ç¤ºé‚®ä»¶å†…å®¹é¢„è§ˆ
                            st.session_state.email_draft_content = email_content

                            # ä½¿ç”¨å®¹å™¨æ¥æ˜¾ç¤ºçŠ¶æ€æ¶ˆæ¯ï¼Œé¿å…é¡µé¢è·³è½¬
                            success_container = st.container()
                            with success_container:
                                st.success("âœ… é‚®ä»¶è‰ç¨¿å·²ç”Ÿæˆï¼")

                            # å°è¯•æ‰“å¼€é‚®ä»¶å®¢æˆ·ç«¯
                            if open_email_client(email_content):
                                info_container = st.container()
                                with info_container:
                                    st.info("ğŸ“§ å·²å°è¯•æ‰“å¼€é»˜è®¤é‚®ä»¶å®¢æˆ·ç«¯")
                            else:
                                warning_container = st.container()
                                with warning_container:
                                    st.warning("âš ï¸ æ— æ³•æ‰“å¼€é‚®ä»¶å®¢æˆ·ç«¯ï¼Œè¯·æŸ¥çœ‹ä¸‹æ–¹é‚®ä»¶å†…å®¹")
                        else:
                            error_container = st.container()
                            with error_container:
                                st.error("âŒ ç”Ÿæˆé‚®ä»¶è‰ç¨¿å¤±è´¥")

                    # å¦‚æœæŒ‰é’®è¢«ç‚¹å‡»è¿‡ï¼Œæ˜¾ç¤ºé‡ç½®é€‰é¡¹
                    if st.session_state.email_button_clicked:
                        if st.button("ğŸ”„ é‡ç½®", key="reset_email_button", help="é‡ç½®é‚®ä»¶ç”ŸæˆçŠ¶æ€"):
                            st.session_state.email_button_clicked = False
                            if 'email_draft_content' in st.session_state:
                                del st.session_state.email_draft_content
                            st.rerun()

                # æ˜¾ç¤ºé‚®ä»¶å†…å®¹é¢„è§ˆ
                if 'email_draft_content' in st.session_state:
                    st.markdown("### é‚®ä»¶è‰ç¨¿é¢„è§ˆ")
                    st.text_area(
                        "é‚®ä»¶å†…å®¹",
                        st.session_state.email_draft_content,
                        height=300,
                        help="æ‚¨å¯ä»¥å¤åˆ¶æ­¤å†…å®¹åˆ°é‚®ä»¶å®¢æˆ·ç«¯",
                        key="diff_email_preview"
                    )
            else:
                st.success("æ²¡æœ‰å‘ç°å·®å¼‚")
        except Exception as e:
            st.error(f"æ— æ³•åŠ è½½å·®å¼‚æŠ¥å‘Š: {str(e)}")
    else:
        st.info("è¯·å…ˆå¤„ç†æ•°æ®")

# Logs Tab
with tab5:
    st.markdown("<h2 class='sub-header'>å¤„ç†æ—¥å¿—</h2>", unsafe_allow_html=True)

    # List all log files
    log_files = sorted([f for f in os.listdir(log_dir) if f.endswith('.log')], reverse=True)

    if log_files:
        selected_log = st.selectbox("é€‰æ‹©æ—¥å¿—æ–‡ä»¶", log_files)
        log_path = os.path.join(log_dir, selected_log)

        try:
            with open(log_path, 'r', encoding='utf-8') as f:
                log_content = f.read()

            # Add filter options
            filter_options = st.multiselect(
                "ç­›é€‰æ—¥å¿—çº§åˆ«",
                ["INFO", "WARNING", "ERROR"],
                default=["WARNING", "ERROR"]
            )

            # Filter log content
            filtered_lines = []
            for line in log_content.split('\n'):
                if any(level in line for level in filter_options):
                    filtered_lines.append(line)

            if filtered_lines:
                st.text_area("æ—¥å¿—å†…å®¹", '\n'.join(filtered_lines), height=400)
            else:
                st.info("æ²¡æœ‰ç¬¦åˆç­›é€‰æ¡ä»¶çš„æ—¥å¿—")

            # Download button for log file
            with open(log_path, "rb") as file:
                st.download_button(
                    label="ä¸‹è½½å®Œæ•´æ—¥å¿—æ–‡ä»¶",
                    data=file,
                    file_name=selected_log,
                    mime="text/plain"
                )
        except Exception as e:
            st.error(f"æ— æ³•è¯»å–æ—¥å¿—æ–‡ä»¶: {str(e)}")
    else:
        st.info("æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—æ–‡ä»¶")

# Footer
st.markdown("---")

# è‡ªåŠ¨ä¸‹è½½æ¯”å¯¹æŠ¥å‘Š
if 'show_download_button' in st.session_state and st.session_state.show_download_button:
    if 'auto_download_report' in st.session_state:
        st.success("å¤„ç†å®Œæˆï¼æ¯”å¯¹æŠ¥å‘Šå·²å‡†å¤‡å¥½ä¸‹è½½")

        col1, col2 = st.columns(2)

        with col1:
            # ä½¿ç”¨session stateæ¥ç®¡ç†ä¸‹è½½çŠ¶æ€ï¼Œé¿å…é¡µé¢è·³è½¬
            # åˆå§‹åŒ–ä¸‹è½½çŠ¶æ€
            if 'download_clicked' not in st.session_state:
                st.session_state.download_clicked = False

            # åˆ›å»ºä¸‹è½½æŒ‰é’®
            download_button = st.download_button(
                label="ğŸ“¥ ç‚¹å‡»ä¸‹è½½æ¯”å¯¹æŠ¥å‘Š",
                data=st.session_state.auto_download_report,
                file_name="æ¯”å¯¹æŠ¥å‘Š.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key="auto_download_report_button",
                use_container_width=True,
                help="ç‚¹å‡»ä¸‹è½½å·®å¼‚æ¯”å¯¹æŠ¥å‘Šæ–‡ä»¶"
            )

            # å¦‚æœä¸‹è½½æŒ‰é’®è¢«ç‚¹å‡»ï¼Œæ˜¾ç¤ºåé¦ˆ
            if download_button:
                st.session_state.download_clicked = True
                success_container = st.container()
                with success_container:
                    st.success("âœ… æŠ¥å‘Šä¸‹è½½å·²å¼€å§‹")
                    st.info(" æ–‡ä»¶å°†ä¿å­˜åˆ°æ‚¨çš„é»˜è®¤ä¸‹è½½æ–‡ä»¶å¤¹")

        with col2:
            # ä½¿ç”¨session stateæ¥ç®¡ç†é‚®ä»¶ç”ŸæˆçŠ¶æ€ï¼Œé¿å…é¡µé¢è·³è½¬
            if 'show_email_button' in st.session_state and st.session_state.show_email_button:
                # æ£€æŸ¥æ˜¯å¦å·²ç»ç”Ÿæˆè¿‡é‚®ä»¶è‰ç¨¿
                if 'email_generated' not in st.session_state:
                    st.session_state.email_generated = False

                # ä½¿ç”¨ä¸åŒçš„æŒ‰é’®æ–‡æœ¬æ¥åæ˜ çŠ¶æ€
                button_label = "ğŸ”„ é‡æ–°ç”Ÿæˆé‚®ä»¶è‰ç¨¿" if st.session_state.email_generated else "ğŸ“§ ç”Ÿæˆé€šçŸ¥é‚®ä»¶è‰ç¨¿"

                if st.button(button_label, type="secondary", key="auto_generate_email_button", use_container_width=True, help="ç”Ÿæˆå¹¶æ‰“å¼€é‚®ä»¶å®¢æˆ·ç«¯"):
                    if 'email_draft_content' in st.session_state:
                        # æ ‡è®°é‚®ä»¶å·²ç”Ÿæˆ
                        st.session_state.email_generated = True

                        # ä½¿ç”¨å®¹å™¨æ¥æ˜¾ç¤ºçŠ¶æ€æ¶ˆæ¯ï¼Œé¿å…é¡µé¢è·³è½¬
                        success_container = st.container()
                        with success_container:
                            st.success("âœ… é‚®ä»¶è‰ç¨¿å·²å‡†å¤‡å°±ç»ª")

                        # å°è¯•æ‰“å¼€é‚®ä»¶å®¢æˆ·ç«¯
                        if open_email_client(st.session_state.email_draft_content):
                            info_container = st.container()
                            with info_container:
                                st.info("ğŸ“§ å·²æ‰“å¼€é»˜è®¤é‚®ä»¶å®¢æˆ·ç«¯")
                        else:
                            warning_container = st.container()
                            with warning_container:
                                st.warning("âš ï¸ æ— æ³•æ‰“å¼€é‚®ä»¶å®¢æˆ·ç«¯ï¼Œè¯·æŸ¥çœ‹ä¸‹æ–¹é‚®ä»¶å†…å®¹")
                    else:
                        error_container = st.container()
                        with error_container:
                            st.error("âŒ é‚®ä»¶è‰ç¨¿å†…å®¹ä¸å¯ç”¨ï¼Œè¯·é‡æ–°å¤„ç†æ•°æ®")

# æ˜¾ç¤ºè‡ªåŠ¨ç”Ÿæˆçš„é‚®ä»¶è‰ç¨¿é¢„è§ˆ - ä½¿ç”¨session stateæ§åˆ¶æ˜¾ç¤º
if 'email_draft_content' in st.session_state and st.session_state.email_draft_content:
    st.markdown("### ğŸ“§ é‚®ä»¶è‰ç¨¿å·²è‡ªåŠ¨ç”Ÿæˆ")
    with st.expander("æŸ¥çœ‹é‚®ä»¶å†…å®¹", expanded=False):
        st.text_area(
            "é‚®ä»¶å†…å®¹",
            st.session_state.email_draft_content,
            height=200,
            help="æ‚¨å¯ä»¥å¤åˆ¶æ­¤å†…å®¹åˆ°é‚®ä»¶å®¢æˆ·ç«¯",
            key="auto_email_preview",
            disabled=True  # è®¾ç½®ä¸ºåªè¯»ï¼Œé¿å…æ„å¤–ä¿®æ”¹
        )

st.markdown("Â© 2025 Checklistæ ¸å¯¹ç³»ç»Ÿ | ç‰ˆæœ¬ 1.2")